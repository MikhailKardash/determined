name: cifar10_pytorch_distributed
hyperparameters:
  learning_rate: 1.0e-4
  learning_rate_decay: 1.0e-6
  layer1_dropout: 0.25
  layer2_dropout: 0.25
  layer3_dropout: 0.5
  global_batch_size: 64 # Per-GPU batch size of 32
resources:
  slots_per_trial: 2
records_per_epoch: 500
searcher:
  name: single
  metric: validation_error
  max_length:
    epochs: 1
entrypoint: python -m determined.launch.torch_distributed model_def.py
min_validation_period:
  epochs: 1
max_restarts: 0
